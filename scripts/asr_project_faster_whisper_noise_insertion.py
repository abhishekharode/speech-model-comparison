# -*- coding: utf-8 -*-
"""ASR_Project_Faster_Whisper(Noise insertion)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lnsbhnAkmjGWekcIOyxuBhHAbpCJ7V1D
"""

!pip install -q openai-whisper
!pip install -q faster-whisper
!pip install -q transformers datasets evaluate jiwer torchaudio psutil

import torch
import time
import psutil
import os
import numpy as np
import pandas as pd

from datasets import load_dataset
from jiwer import wer

print("GPU Available:", torch.cuda.is_available())

if torch.cuda.is_available():
    print("GPU Name:", torch.cuda.get_device_name(0))
    print("CUDA Version:", torch.version.cuda)

from datasets import load_dataset, Audio

dataset = load_dataset(
    "librispeech_asr",
    "clean",
    split="test[:50]"
)

dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))

print("Total Samples:", len(dataset))

from faster_whisper import WhisperModel

device = "cuda" if torch.cuda.is_available() else "cpu"

faster_model = WhisperModel(
    "small",
    device=device,
    compute_type="float16"
)

print("Faster-Whisper model loaded.")

import numpy as np

def add_noise(audio, snr_db):

    audio = audio.astype(np.float32)

    audio_power = np.mean(audio**2)
    snr_linear = 10 ** (snr_db / 10)
    noise_power = audio_power / snr_linear

    noise = np.random.normal(0, np.sqrt(noise_power), len(audio))
    noisy_audio = audio + noise

    return noisy_audio.astype(np.float32)

import re
import time
import pandas as pd

def normalize_text(text):
    text = text.lower()
    text = re.sub(r"[^\w\s]", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

snr_levels = [20, 10, 5]

for snr_level in snr_levels:

    print(f"\n==============================")
    print(f"Running for SNR = {snr_level} dB")
    print(f"==============================")

    results = []

    for idx, sample in enumerate(dataset):

        clean_audio = sample["audio"]["array"]
        audio = add_noise(clean_audio, snr_level)

        sr = sample["audio"]["sampling_rate"]
        reference = sample["text"]

        audio_duration = len(audio) / sr

        start_time = time.time()

        segments, info = faster_model.transcribe(audio)

        prediction = ""
        for segment in segments:
            prediction += segment.text

        inference_time = time.time() - start_time

        reference_norm = normalize_text(reference)
        prediction_norm = normalize_text(prediction)

        sample_wer = wer(reference_norm, prediction_norm)
        rtf = inference_time / audio_duration

        results.append({
            "id": idx,
            "wer": sample_wer,
            "inference_time": inference_time,
            "audio_duration": audio_duration,
            "rtf": rtf
        })

        print(f"Processed sample {idx}")

    df = pd.DataFrame(results)

    print("\n--- RESULTS ---")
    print("Average WER:", df["wer"].mean())
    print("Average Inference Time:", df["inference_time"].mean())
    print("Average RTF:", df["rtf"].mean())